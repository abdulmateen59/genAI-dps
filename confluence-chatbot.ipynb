{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e103bc-1f9b-4348-bf17-09d2d32fed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from IPython.display import display_markdown\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import ConfluenceLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "import vertexai\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\"\n",
    "vertexai.init(project=\"\", location=\"europe-west3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19ab73-5f9d-4f0d-a80d-c49d502d9fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = ConfluenceLoader(\n",
    "    url=\"\",\n",
    "    token=\"\"\n",
    ")\n",
    "docs = loader.load(\n",
    "    space_key=\"\",\n",
    "    # include_attachments=True, # uncomment to include png, jpeg, ..\n",
    "    keep_markdown_format=True\n",
    ")\n",
    "\n",
    "print(\"Content: \\n ------- \\n\" + docs[-1].page_content)\n",
    "print(\"Metadatas: \\n ------- \\n\" + str(docs[-1].metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded8289-b075-4ac8-aee9-b5a06230e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(chunks):\n",
    "    print(\n",
    "        str('\\n' + '='*50 + '\\n').join(\n",
    "            [ chunk.page_content + '\\n' +'-'*50 + '\\n' + str(chunk.metadata)  for chunk in chunks ]\n",
    "        )\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993fabc-5213-4e2e-b280-e8eaadfc11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "# I am a title \n",
    "## I am a subtitle\n",
    "I am a block of text. However, my size is quite long. First of all, I'd like the MarkdownHeaderTextSplitter\n",
    "to identify my title and subtitle in its metadata.\n",
    "Then I'd like the RecursiveCharacterTextSplitter to identify the two parts that make up my text \n",
    "because my size would be too large to feed a language model. \n",
    "Finally, I'd like the metadata corresponding to my origins, i.e. the url, to be merged with my\n",
    "title and subtitle information.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "metadata={'url': 'https://abdul-mateen.com'}\n",
    "sample = Document(page_content=text, metadata=metadata)\n",
    "\n",
    "# Markdown \n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Title 1\"),\n",
    "    (\"##\", \"Sub-title 1\"),\n",
    "    (\"###\", \"Sub-title 2\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Split based on markdown and add original metadata\n",
    "md_docs = []\n",
    "for doc in [sample]:\n",
    "    md_doc = markdown_splitter.split_text(doc.page_content)\n",
    "    for i in range(len(md_doc)):\n",
    "        md_doc[i].metadata = md_doc[i].metadata | doc.metadata \n",
    "    md_docs.extend(md_doc)\n",
    "\n",
    "\n",
    "# Chunk size big enough\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "splitted_docs = splitter.split_documents(md_docs)\n",
    "\n",
    "pretty_print(splitted_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_documents(docs)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d581f-308b-4998-abce-05ee7943df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d662a-736e-4a5b-bf52-0329d78b9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save db \n",
    "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_db\")\n",
    "db.persist()\n",
    "# db._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87308ae-214d-4d74-acb8-c1d36078c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.get()\n",
    "retriever = db.as_retriever()\n",
    "# retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 5, \"score_threshold\": 0.3})\n",
    "template = \"\"\"Given this text extracts:\n",
    "    -----\n",
    "    {context}\n",
    "    -----\n",
    "    Please answer with to the following question:\n",
    "    Question: {question}\n",
    "    Answer: \n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "# LLM\n",
    "llm = VertexAI(model_name=\"gemini-pro\", temperature=0.6)\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d7e1a-70ab-49ff-a127-7269e7ddc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"How to create service account for sisense?\"\n",
    "q2 = \"Tell me about Tech lead role?\"\n",
    "q3= \"what is daily duty person checklist?\"\n",
    "q4= \"How to offboard a team member?\"\n",
    "\n",
    "\n",
    "answer = qa({\"query\": q4})\n",
    "\n",
    "display_markdown(answer[\"result\"], raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813848c-a6dd-44ca-a1e2-c37a3463e54d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(q4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
